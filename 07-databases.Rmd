# Databases {#databases}

Written by Nathan Muncy.

This chapter is under construction

A [MySQL](https://dev.mysql.com/doc/) server is installed on labarserv2 which allows for project data to be stored within a relational database management system ([RDBMS](https://en.wikipedia.org/wiki/Relational_database)). Utilizing a RDBMS allows the researcher to centralize, better manage, flexibly access, and share their data. Additionally, the dedicated structures will help maintain data consistency across users and projects.

This chapter will serve as a brief tutorial and reference for setting up and then using project-specific databases.


## Create an Account

Admins of labarserv2 create accounts and grant access to the mysql server and databases. Start by logging into the server as admin `$sudo mysql`.

Current user and host information are available at `mysql.user`:

```
use mysql;
select user, host from user;
```

To [create a user](https://dev.mysql.com/doc/refman/8.0/en/create-user.html) ('test') identified by a password ('foobar'), specify the new user name, host or IP, and password:

```
create user 'test'@'localhost' identified by 'foobar';
create user 'test'@'127.0.0.1' identified by 'foobar';
```

Next, permissions to a specific database ('db_test'), and also tables if desired, can be [granted](https://dev.mysql.com/doc/refman/8.0/en/grant.html):

```
grant insert, update, select, references,
  create temporary tables,
  on db_test.*
  to 'test'@'localhost'; -- give select permissions
grant all on db_test.* to 'test'@'localhost'; -- give all permissions
```

Finally, check that appropriate permissions have been added to the user account and then apply the changes to the server:

```
show grants for 'test'@'localhost';
flush privileges;
```

The user should then be able to login to the server via `$mysql -u test -p`, enter their password (foobar), and access the database (`use db_test; show tables;`).


## Login {#login}

Users that have an account can login to the mysql server via

`$mysql -u user_name -p`

and then supply their password when prompted. Databases to which the user has access can be listed via `show databases;`. After selecting a database for use (`use db_some_name;`), available tables can be listed via `show tables;`.

A database can also be specified at login:

`$mysql -u user_name -p db_some_name`

Exit the server via `exit;` or `quit;`.


## Create a Database {#create_database}

Admin (i.e. all) privileges are needed by the user to create an database. Accordingly, it is most likely best for labarserv2 admins to create databases and then grant specific (or all) permissions to the user for the specific database.

[Database creation](https://dev.mysql.com/doc/refman/8.0/en/creating-database.html) is accomplished simply via:

`create database db_some_name;`

**Conventions** - The following database conventions are implemented in the LaBar Lab:

* Database names start with `db`, e.g. `db_project1` and `db_project2`. This allows for project databases to be identified separately while also being distinct from admin and schema databases
* Separate databases are made for separate projects, that is, one project should not span multiple databases
* Database names are succinct, being both descriptive and as short as is reasonable
* Databases are named in snake case (`db_emotion_regulation` and not `db-emotion-regulation`)


## Create a Table {#create_table}

[Tables](https://dev.mysql.com/doc/refman/8.0/en/creating-tables.html) are 2-dimensional matrices containing rows and columns of data. Each row must contain unique information and each column contains only one [data type](https://dev.mysql.com/doc/refman/8.0/en/data-types.html). Whether to use long- or wide-formatted tables depends on the user and nature of the data, but long-formatted tables (or at least [tidy](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)) is preferable and generally more flexible.

The `create table` syntax is used within a database to both create the table and specify the number and types of columns. Three types of tables ([reference](#reference_tables), [data](#data_tables), and [definition](#definition_tables)) are used in the LaBar Lab, which are prepended with `ref_`, `tbl_`, and `def_` identifiers, respectively.


### Reference Tables {#reference_tables}

When a certain value, such as a participant ID or emotion name, show up across multiple data tables, the value can be stored in a reference table rather than be used repeatedly across multiple tables. These reference tables, and the fact that values from multiple databases can be queried at once, are the point of RDBMSs. As an added perk, the size of the database is also decreased as redundant values are minimized.

Say a project intends to gather information across multiple subjects, each of whom will participate in three sessions, and some measures will occur during all sessions. We can then set up reference tables for the subject IDs, session IDs, and emotion IDs as these values would be common across all measures.

To start a reference table for subject IDs, then:

```
use db_test;
create table ref_subj (
  subj_id int not null,
  subj_name char(4) not null,
  primary key(subj_id)
);
```
Here we created the table `ref_subj` in the database `db_test`. This table contains two columns: the first column is titled `subj_id`, is integer type, and does not allow null values. The second column is titled `subj_name`, the value uses exactly 4 characters, and also null values are also not allowed. Finally, the [primary key](https://www.mysqltutorial.org/mysql-basics/mysql-primary-key/) is set to reference the 'subj_id' column. This key is used to uniquely identify each row in the table, and will serve as the reference value across database tables, and note that `not null` is required for primary keys.

A description of the table is available via the `describe table_name` command:

```
mysql> describe ref_subj;
+-----------+---------+------+-----+---------+-------+
| Field     | Type    | Null | Key | Default | Extra |
+-----------+---------+------+-----+---------+-------+
| subj_id   | int     | NO   | PRI | NULL    |       |
| subj_name | char(4) | NO   |     | NULL    |       |
+-----------+---------+------+-----+---------+-------+
2 rows in set (0.01 sec)
```

**Conventions** - The following reference table conventions are implemented in the LaBar Lab:

* The table name starts with 'ref_'
* The name for columns involved in the primary key ends in '_id'
* The value which corresponds to the primary key ends in '_name'
* The table name is reflected in column names when possible (e.g. 'subj')

Following these conventions will increase the ease of joining tables and allow other researchers to more readily understand the data structure.

Data can then be added to the table via `insert` by specifying the desired columns and input values:

```
insert into ref_subj
  (subj_id, subj_name)
  values
  (1, "SUB1"),
  (2, "SUB2"),
  (3, "SUB3"),
  (4, "SUB4");
```

Check that the reference table is properly specified via `select`:

```
mysql> select * from ref_subj;
+---------+-----------+
| subj_id | subj_name |
+---------+-----------+
|       1 | SUB1      |
|       2 | SUB2      |
|       3 | SUB3      |
|       4 | SUB4      |
+---------+-----------+
4 rows in set (0.00 sec)
```

The other reference tables, for session and emotion, can likewise be built (note the variable emotion name length):

```
-- Session reference
create table ref_sess (
    sess_id int not null,
    sess_name char(4) not null,
    primary key(sess_id)
);
insert into ref_sess
    (sess_id, sess_name)
    values
    (1, "day1"),
    (2, "day2"),
    (3, "day3");

-- Emotion reference
create table ref_emo (
    emo_id int not null,
    emo_name varchar(10) not null,
    primary key(emo_id)
);
insert into ref_emo
    (emo_id, emo_name)
    values
    (1, "amusement"),
    (2, "anger"),
    (3, "anxiety"),
    (4, "awe"),
    (5, "calmness"),
    (6, "craving"),
    (7, "disgust"),
    (8, "excitement"),
    (9, "fear"),
    (10, "horror"),
    (11, "joy"),
    (12, "neutral"),
    (13, "romance"),
    (14, "sadness"),
    (15, "surprise");
```


### Data Tables {#data_tables}

Continuing with the example started above, data from each measure collected is stored in data tables, with repeated values linked to reference tables. Building data tables uses the same methodology described above, with the addition of specifying [foreign keys](https://www.cockroachlabs.com/blog/what-is-a-foreign-key/) and thus begin to make our database relational.

Let us suppose that for each session our participants supply PANAS and ERQ ratings as well as a hypothetical in-house measure (EmoFreq) during which participants are prompted to respond how frequently, intensely, and saliently they felt a given emotion (`ref_emo`) over the previous week.

Using the `create table` syntax, again, we first build a data table for the PANAS questionnaire:

```
create table tbl_panas (
    subj_id int not null,
    sess_id int not null,
    item_panas int not null,
    resp_panas int,
    primary key(subj_id, sess_id, item_panas),
    foreign key(subj_id) references ref_subj(subj_id) on delete cascade,
    foreign key(sess_id) references ref_sess(sess_id)
);
```

Here we created a long-formatted table containing four columns -- one for the subject identifier (`subj_id`), session identifier (`sess_id`), PANAS item/prompt (`item_panas`), and participant response to PANAS item/prompt (`resp_panas`). Participant responses are recorded as integer type, and only the PANAS item number (integer) is used -- if it was desired to keep the question syntax rather than item number then a reference table could be set up (e.g. `ref_panas`, see conventions [above](#reference_tables)) and this column would then be named `panas_id`. Also note that `item_panas` is specified as `not null` as participants will see every PANAS item (and this column is used in the primary key). Finally, as participants may not respond to each item `resp_panas` allows for null values. 

The [primary key](https://www.mysqltutorial.org/mysql-basics/mysql-primary-key/) is specified here as the composition of subject, session, and PANAS item (sometimes termed a 'composite key' or 'natural key') and serves as as the unique identifier for each participant response. It is [recommended](https://dev.mysql.com/doc/refman/8.0/en/primary-key-optimization.html) to always explicitly specify your primary key. Additionally, explicitly controlling keys helps in setting up proper [relationship mappings](https://www.tutorialsteacher.com/sqlserver/tables-relations). If a natural key ought not to be used for a primary key, or data naturally increment, then a column could be set to [auto increment](https://dev.mysql.com/doc/refman/8.0/en/example-auto-increment.html) and serve as the primary key.

[Foreign keys](https://dev.mysql.com/doc/refman/8.0/en/create-table-foreign-keys.html) are used to reflect that a column is linked to another table, and can also be used to constrain column values (not demonstrated). Here, the columns `subj_id` and `sess_id` will not be populated with the actual subject and session names/values, as that would involve a lot of repetitive information, but instead their respective reference table ID. Specifically, we set the `subj_id` column (`tbl_panas.subj_id`) to reference the `subj_id` column of `ref_subj` (`ref_subj.subj_id`). Similarly `tbl_panas.sess_id` references `ref_sess.sess_id`. Finally, [`on delete cascade`](https://www.mysqltutorial.org/mysql-basics/mysql-on-delete-cascade/) allows records from this current table to be removed if the referenced value in `ref_subj` is deleted (perhaps due to participant withdrawal).

**Conventions** - The following data tables conventions are implemented in the LaBar Lab:

* The table name starts with 'tbl_'
* The measure name is reflected in the table name and relevant columns when possible (e.g. 'panas')
* The name for columns that become a foreign key end in '_id' when possible
* Column names for measure identifiers start with 'item_'
* Participant responses start with 'resp_'

The data tables for the ERQ and in-house EmoFreq surveys can also be made in similar fashion:

```
-- ERQ table
create table tbl_erq (
    subj_id int not null,
    sess_id int not null,
    item_erq int not null,
    resp_erq int,
    primary key(subj_id, sess_id, item_erq),
    foreign key(subj_id) references ref_subj(subj_id) on delete cascade,
    foreign key(sess_id) references ref_sess(sess_id)
);

-- EmoFreq table
create table tbl_emofreq (
    subj_id int not null,
    sess_id int not null,
    emo_id int not null,
    resp_frq int,
    resp_int int,
    resp_sal int,
    primary key(subj_id, sess_id, emo_id),
    foreign key(subj_id) references ref_subj(subj_id) on delete cascade,
    foreign key(sess_id) references ref_sess(sess_id),
    foreign key(emo_id) references ref_emo(emo_id)
);
```

For the in-house EmoFreq measure, where participants are prompted with an emotion and they respond how frequently, intensely, and saliently they experienced the emotion over the previous week, the 'item_' column was omitted and replaced with the foreign key `emo_id` as the prompt is simply the emotion name. Additionally, better names for the response columns could have been `resp_emofreq_frequency` etc., particularly if other measures elicit similar responses. This was omitted to illustrate the utility of definition tables.

Finally, following foreign keys to their source is available in the `information_schema` database:

```
SELECT
  `TABLE_SCHEMA`,
  `TABLE_NAME`,
  `COLUMN_NAME`,
  `REFERENCED_TABLE_SCHEMA`,
  `REFERENCED_TABLE_NAME`,
  `REFERENCED_COLUMN_NAME`
FROM
  `INFORMATION_SCHEMA`.`KEY_COLUMN_USAGE`
WHERE
  `TABLE_SCHEMA` = SCHEMA()
  AND `REFERENCED_TABLE_NAME` IS NOT NULL;
```

which yields:

```
+--------------+-------------+-------------+-------------------------+-----------------------+------------------------+
| TABLE_SCHEMA | TABLE_NAME  | COLUMN_NAME | REFERENCED_TABLE_SCHEMA | REFERENCED_TABLE_NAME | REFERENCED_COLUMN_NAME |
+--------------+-------------+-------------+-------------------------+-----------------------+------------------------+
| db_test      | tbl_emofreq | subj_id     | db_test                 | ref_subj              | subj_id                |
| db_test      | tbl_emofreq | sess_id     | db_test                 | ref_sess              | sess_id                |
| db_test      | tbl_emofreq | emo_id      | db_test                 | ref_emo               | emo_id                 |
| db_test      | tbl_erq     | subj_id     | db_test                 | ref_subj              | subj_id                |
| db_test      | tbl_erq     | sess_id     | db_test                 | ref_sess              | sess_id                |
| db_test      | tbl_panas   | subj_id     | db_test                 | ref_subj              | subj_id                |
| db_test      | tbl_panas   | sess_id     | db_test                 | ref_sess              | sess_id                |
+--------------+-------------+-------------+-------------------------+-----------------------+------------------------+
7 rows in set (0.00 sec)
```

This is useful when tracking the relationship mappings (such as when working with a new database or when table/column names are less-than-helpful), and requires the `references` grant for the user.


### Definition Tables {#definition_tables}

Few things are more frustrating when working within RDBMSs than not understanding column names nor knowing what data they contain. This is compounded by less-than-intuitive column names that are sometimes required for the sake of brevity, as is commonly the case when working on larger projects. Definition tables help assuage these frustrations by supplying definitions or explanations of column names and purpose.

As the data table `tbl_emofreq` (above) has some column names that may be unintuitive, we will specify a definition table to aid in interpreting the table: 

```
create table def_emofreq (
    col_name enum('resp_frq', 'resp_int', 'resp_sal'),
    col_desc text
);
```

This definition table contains two columns, `col_name` and `col_desc`. Column `col_name` is specified to only accept certain values via [enum](https://dev.mysql.com/doc/refman/8.0/en/enum.html), which values correspond to the confusing column names in `tbl_emofreq`. Column `col_desc` is set to use the [text type](https://dev.mysql.com/doc/refman/8.0/en/string-type-syntax.html), which will allow for more verbose strings. A primary key has not been set as this table is not meant to be integrated with other tables but instead to be read by the researcher.

**Conventions** - The following definition table conventions are implemented in the LaBar Lab:

* A definition table should exist for every data table that does not hold standardized items (e.g. PANAS, ERQ) that could be looked up in a resource (but a definition table is still recommended).
* Definition tables should not be used to hold item interpretations, e.g. storing what is meant when `tbl_panas.item_panas = 1` (the text of the PANAS's first item). These belong in a reference table.
* The table uses the same name as the data table, but replacing 'tbl_' with 'def_'.
* The table contains the column `col_name`, which itself only contains the names of columns from the data table.
* All columns not involved in ID from the data table are specified in `col_name`.
* The table contains the column `col_desc`, which holds a human-readable description of the column.
* Additional columns can be add using the `col_` format, when required.

The definition table `def_emofreq` can now be populated with text:

```
insert into def_emofreq
    (col_name, col_desc)
    values
    ('resp_frq', 'Participant response to frequency prompt'),
    ('resp_int', 'Participant response to intensity prompt'),
    ('resp_sal', 'Participant response to salience prompt');
```


## Insert Data

Adding data to a table is 

Building on our example for building [databases](#create_database) and [tables](#create_table), now that a database and tables are properly specified we can begin adding data to the tables. Add data is easily accomplished via the [`insert into`](https://dev.mysql.com/doc/refman/8.0/en/insert.html) command, and we have seen a few examples already when building the [reference](#reference_tables) and [definition](#definition_tables) tables.

To add a single row (or several) of data into a table, we specify the table, columns, and values:

```
use db_test;
insert ignore into tbl_erq
  (subj_id, sess_id, item_erq, resp_erq)
  values
  (1, 1, 1, 6),
  (1, 2, 1, 4),
  (1, 3, 1, 2);
```

Working within our example database `db_test` we have add three new rows of data to `tbl_erq`. The `insert ignore into` skips the insertion if the same values already exist, avoiding overwriting existing data in `tbl_erq`. The relevant columns were referenced, and then participant 1 (ref `ref_subj.subj_name`) responses to the first ERQ item were added for each session. We can check that the insertion was successful by selecting our data:

```
mysql> select * from tbl_erq;
+---------+---------+----------+----------+
| subj_id | sess_id | item_erq | resp_erq |
+---------+---------+----------+----------+
|       1 |       1 |        1 |        6 |
|       1 |       2 |        1 |        4 |
|       1 |       3 |        1 |        2 |
+---------+---------+----------+----------+
3 rows in set (0.01 sec)
```

Obviously, manually entering every row is untenable and error prone. The insert command of single rows was shown for practice and also to be leveraged algorithmically in a workflow.

Additionally, if CSV files (or similar formats) already exist in the same format as your table, then entire tables can be inserted as well. The following shell syntax can be used to generate some random data: and note that a row will be skipped during `load data` if the `subj_id` does not appear in `ref_subj`:

```
#!/bin/bash

echo "subj_id,sess_id,item_erq,resp_erq" >${HOME}/Desktop/erq_data.csv
for subj in {1..9}; do
    for sess in {1..3}; do
        for item in {1..10}; do
            resp=$(((RANDOM % 10) + 1))
            echo "${subj},${sess},${item},${resp}" >>${HOME}/Desktop/erq_data.csv
        done
    done
done
```

Having built appropriate files for `tbl_panas`, `tbl_erq`, and `tbl_emofreq`, and assuming that [local infiles are allowed](https://stackoverflow.com/questions/59993844/error-loading-local-data-is-disabled-this-must-be-enabled-on-both-the-client), I can then [login](#login) to the server using the local-infile option that allows the server to read a file on my local machine.

```
$mysql --local-infile=1 -u nate -p db_test
```

Entire CSVs from the Desktop can now be loaded via the [`load data`](https://dev.mysql.com/doc/refman/8.0/en/load-data.html) command (and note that rows will be skipped for `subj_id` values not found in `ref_subj`):

```
delete from tbl_erq; --clear example inputs

load data local infile '/home/Nathan/Desktop/erq_data.csv'
into table tbl_erq
fields terminated by ','
enclosed by '"'
lines terminated by '\n'
ignore 1 rows;
```

As specified, `local infile` supplies the path to the CSV file, and then extra options are specified help parse the file such as specifying that the CSV is comma-delimited, strings are enclosed by a double quote, line endings use a linefeed, and a header exists in the CSV. 

This method is faster then repeated insertions and is the preferred method if manually porting data. We can again verify that the table was updated, but limit the return to 10 rows:

```
mysql> select * from tbl_erq limit 10;
+---------+---------+----------+----------+
| subj_id | sess_id | item_erq | resp_erq |
+---------+---------+----------+----------+
|       1 |       1 |        1 |        6 |
|       1 |       1 |        2 |        3 |
|       1 |       1 |        3 |        6 |
|       1 |       1 |        4 |        1 |
|       1 |       1 |        5 |        3 |
|       1 |       1 |        6 |        1 |
|       1 |       1 |        7 |        5 |
|       1 |       1 |        8 |        5 |
|       1 |       1 |        9 |        3 |
|       1 |       1 |       10 |        5 |
+---------+---------+----------+----------+
10 rows in set (0.00 sec)
```

